{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd0b60a-8078-4cb2-8473-17480a93fb83",
   "metadata": {},
   "source": [
    "# 7 Train And Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d8bd6-6067-488a-a103-b4103e4c6930",
   "metadata": {},
   "source": [
    "# story for ML \n",
    "- Father => To train to his son to recognize cat/dog\n",
    "- Images => Data - 100\n",
    "\n",
    "# - Splitting the Data => ratio = 70 + 30\n",
    "\n",
    "- Training => 70%\n",
    "\n",
    "- Testing => 30%\n",
    "\n",
    "- With train data => We need to train model(ML alg)\n",
    "\n",
    "- Before training => Model donot know anything == 0 Know\n",
    "\n",
    "- After training => Model know everything about the data\n",
    "\n",
    "- Check accuracy => We need to the model\n",
    "\n",
    "- Testing => 30% data we need to use for testing\n",
    "\n",
    "- If accuracy => Good then deploy the model\n",
    "\n",
    "- If accuracyb => Not good then retrain the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a381fb-2dae-4bb2-9b8f-c6ce39dea256",
   "metadata": {},
   "source": [
    "# Machine Learning Steps\n",
    "### 1. Importing libraries\n",
    "### 2. Loading the datasets\n",
    "### 3. Data preparation\n",
    "# 4. Splitting the dataset  => Train and Test Datasets\n",
    "### 5. Creating the model (Algorithm)\n",
    "### 6. Model training\n",
    "### 7. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba79ba-621d-4d79-a22d-48c68a540cad",
   "metadata": {},
   "source": [
    "## 1 Types of Dataset in Machine learning\n",
    "- There are mainly 3 types of datasets used in Machine learning\n",
    "  1. Train dataset\n",
    "  2. Test dataset\n",
    "  3. Validation dataset\n",
    "- Note\n",
    "  1. Here validation dataset is an optional but training and test datasets are mandatory\n",
    "  2. Dataset will be 100% , Training set 70% test set 30%\n",
    "\n",
    "## 2 Train Dataset \n",
    "- Train dataset is used to train the models\n",
    "- This is the part of dataset which is used to train the model\n",
    "- Typically training set contains about 60-70% of the total dataset\n",
    "- First setps is model should get train with training dataset durining training model learn the paramenters and underlying concepts from dataset\n",
    "\n",
    "## 3 Test dataset \n",
    "- Test Dataset is used to test the model\n",
    "- Once model training is done then we need to test the model with test dataset\n",
    "- During testing the model we will understand about modele performance either good or not\n",
    "- Size of test set is about 15-30% of total dataset\n",
    "\n",
    "## 4 How to decide size of these 3 sets?\n",
    "- There is no thumb rule about chossing the size of these sets, but according to the erperts '70-30' or 60-40 is a good size for train and test set respectively\n",
    "\n",
    "## Creating array\n",
    "- We can create an array and split that array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c811fff-f9ce-4da6-8b78-79868b12656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Createing an array\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(10)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335b0cd-1e91-4803-ab6d-cd18f9043a5d",
   "metadata": {},
   "source": [
    "## 6 train_test_split(p) function\n",
    "- train_test_split(p) is a predefined function in sklearn.model_selection package\n",
    "- We need to access this function from sklearn package\n",
    "- By using this function we can split the dataset into train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11b224ea-4d6b-4a9d-9aeb-18d4fe22e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "[array([0, 5, 1, 7, 6, 9, 8]), array([4, 3, 2])]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating an array and splitting dataset \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset=np.arange(10)\n",
    "\n",
    "result=train_test_split(dataset)\n",
    "\n",
    "print(dataset)\n",
    "print()\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "result[0]\n",
    "print()\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa8754f6-df66-4b26-88aa-9a7b58ffa657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 3, 8, 7, 5, 2, 9, 6]\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "a=[1,2,3,4,5,6,7,8,9]\n",
    "shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaffd67-cf9d-4528-9737-23cbeaf09a5b",
   "metadata": {},
   "source": [
    "## train_test_split function can return single value (list having two arrays (train array and test array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28ca7822-37f6-4764-b3fe-fcadfa78f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100]\n",
      "\n",
      "[array([ 84,  76,  39,  91,  36,  64,  99,  21,  10,  44,  26,  75,  17,\n",
      "        63,  68,  25,  30,  78,  86,   6,  96,  12,  90,  65,  23,  32,\n",
      "        53,  15,  37,  16,  74,  48,  88,   1,  51,  11,  40,  83,  14,\n",
      "        18,  35,  95,  24,  50,  87,  41,  80,   3,  19,  89,  31,  55,\n",
      "        62,  27,  29,  61,   2,  59,  42,  52,  67,  70,  71,  79,  34,\n",
      "        38,  60,  92,  82,   9, 100,  93,  20,  33,  72]), array([43, 73,  7, 46, 69,  8, 97, 77, 28, 85, 56,  5, 49, 22, 57, 81, 13,\n",
      "       66, 58,  4, 47, 98, 45, 94, 54])]\n",
      "**************************************************\n",
      "[ 84  76  39  91  36  64  99  21  10  44  26  75  17  63  68  25  30  78\n",
      "  86   6  96  12  90  65  23  32  53  15  37  16  74  48  88   1  51  11\n",
      "  40  83  14  18  35  95  24  50  87  41  80   3  19  89  31  55  62  27\n",
      "  29  61   2  59  42  52  67  70  71  79  34  38  60  92  82   9 100  93\n",
      "  20  33  72]\n",
      "**************************************************\n",
      "[43 73  7 46 69  8 97 77 28 85 56  5 49 22 57 81 13 66 58  4 47 98 45 94\n",
      " 54]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,101)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "result=train_test_split(dataset)\n",
    "print()\n",
    "print(result)\n",
    "print(50*\"*\")\n",
    "print(result[0])\n",
    "print(50*\"*\")\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b5f60d4-8b35-482a-afc0-f72c5b999ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[9 7 3 2 1 6 8]\n",
      "\n",
      "[ 4  5 10]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset)\n",
    "print()\n",
    "print(x_train)\n",
    "print()\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b24d1c-bef6-43a2-bca7-0b2e64b0524f",
   "metadata": {},
   "source": [
    "## train_test_split  function can return mutiple value (list having two arrays (train array and test array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c35b7a-2f7a-4972-bc82-56c45d1cf96c",
   "metadata": {},
   "source": [
    "# train_test_split\n",
    "- this function by default splitting the dataset into => 70:30\n",
    "- Can i split the dataset into => 60:40  (yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8f994b-d7cf-4cc2-964b-5b0f58e65c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[5 4 3 6 1 7] [ 2 10  8  9]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,test_size=4)\n",
    "print()\n",
    "print(x_train,x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62595b6-e199-4188-acec-d5bb8df18d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[ 9 10  6  7  2  1] [3 5 8 4]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,train_size=6)\n",
    "print()\n",
    "print(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f988603f-5867-45f1-8587-ab37169adcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[ 2 10  1  5  6  3] [4 8 9 7]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,test_size=0.4)\n",
    "print()\n",
    "print(x_train,x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00626401-873b-4225-8725-902ddd61066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[4 2 6 1 7 3] [ 8  9  5 10]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,train_size=0.6)\n",
    "print()\n",
    "print(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfe03175-f97b-433a-bab1-4c3ff9c2d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "[ 3 10  7  4] [6 9 1 5]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  (we should not use this because its wasting the dataset)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,train_size=4,test_size=4)\n",
    "print()\n",
    "print(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8ff1fc0-287f-42ef-8e01-a0f6996d0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "test_size=10 should be either positive and smaller than the number of samples 10 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[0;32m----> 9\u001b[0m x_train,x_test\u001b[38;5;241m=\u001b[39mtrain_test_split(dataset,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train,x_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2853\u001b[0m )\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2426\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2418\u001b[0m train_size_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(train_size)\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2421\u001b[0m     test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2422\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2423\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2424\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2425\u001b[0m ):\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test_size, n_samples)\n\u001b[1;32m   2430\u001b[0m     )\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2433\u001b[0m     train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2437\u001b[0m ):\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_size, n_samples)\n\u001b[1;32m   2442\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: test_size=10 should be either positive and smaller than the number of samples 10 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  (error)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,11)\n",
    "print(dataset)\n",
    "\n",
    "x_train,x_test=train_test_split(dataset,train_size=4,test_size=10)\n",
    "print()\n",
    "print(x_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b45b94-7929-43d8-931a-f2c8e1d59bc2",
   "metadata": {},
   "source": [
    "# ValueError: test_size=10 should be either positive and smaller than the number of samples 10 or a float in the (0, 1) range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71444db3-2dfb-49ff-8f55-2bc73bb99489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  \n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,21)\n",
    "\n",
    "print(dataset)  # output is in single row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "847a14e6-a99c-415d-ac54-fc5ca013e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [11 12 13 14 15 16 17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  \n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,21).reshape(2,10)\n",
    "\n",
    "print(dataset)  # output is in two row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd9cf98d-511a-456a-8122-2c5cb617a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 6 16]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]\n",
      " [10 20]]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  \n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,21).reshape(2,10).T\n",
    "\n",
    "print(dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "781fad43-b874-49fd-ad62-4e8c1c9d907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 6 16]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]\n",
      " [10 20]]\n",
      "\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  \n",
    "import numpy as np\n",
    "\n",
    "x=np.arange(1,21).reshape(2,10).T\n",
    "\n",
    "print(x)\n",
    "\n",
    "y=np.arange(10)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abe010-c179-4551-b1de-83811a561d08",
   "metadata": {},
   "source": [
    "# X => called input == always in column format\n",
    "# y => called output == always in row format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cea6bbf7-7800-4309-b07b-cb21b26b336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 6 16]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]\n",
      " [10 20]]\n",
      "\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "****************************************************************************************************\n",
      "[[ 6 16]\n",
      " [10 20]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]]\n",
      "\n",
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]]\n",
      "****************************************************************************************************\n",
      "[5 3 1 2 6 8 0]\n",
      "\n",
      "[9 4 7]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x=np.arange(1,21).reshape(2,10).T\n",
    "\n",
    "print(x)\n",
    "\n",
    "y=np.arange(10)\n",
    "print()\n",
    "print(y)\n",
    "print(100*\"*\")\n",
    "\n",
    "x_train,x_test=train_test_split(x)\n",
    "print(x_train)\n",
    "print()\n",
    "print(x_test)\n",
    "\n",
    "print(100*'*')\n",
    "y_train,y_test=train_test_split(y)\n",
    "print(y_train)\n",
    "print()\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03c465d5-9d6e-438d-bd9f-7f2b2f8f31d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 6 16]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]\n",
      " [10 20]]\n",
      "\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "****************************************************************************************************\n",
      "[[ 5 15]\n",
      " [ 1 11]\n",
      " [ 3 13]\n",
      " [ 9 19]\n",
      " [ 4 14]\n",
      " [ 8 18]\n",
      " [10 20]]\n",
      "\n",
      "[[ 6 16]\n",
      " [ 2 12]\n",
      " [ 7 17]]\n",
      "\n",
      "****************************************************************************************************\n",
      "[4 0 2 8 3 7 9]\n",
      "\n",
      "[5 1 6]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  (imp)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=np.arange(1,21).reshape(2,10).T\n",
    "\n",
    "print(X)\n",
    "\n",
    "y=np.arange(10)\n",
    "print()\n",
    "print(y)\n",
    "print(100*\"*\")\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y)\n",
    "print(X_train)\n",
    "print()\n",
    "print(X_test)\n",
    "print()\n",
    "\n",
    "print(100*\"*\")\n",
    "\n",
    "print(y_train)\n",
    "print()\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb63561-6ca6-4a8e-869b-ed6719a11a1b",
   "metadata": {},
   "source": [
    "# The power of train_test_split\n",
    "## - Can return single values (dataset)\n",
    "## - Can return two values  (x_train,x_test)   \n",
    "## - Can return four value  (x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f489a-6d9d-4605-bf05-672a582206c6",
   "metadata": {},
   "source": [
    "## 7 train_test_split(p,random_state=0) Function  \n",
    "- train_test_split(p,random_state=0) is a predefined function in sklearn.model_selection package\n",
    "- We need to access this function from sklearn package\n",
    "- By using this function we can split the dataset into train dataset and test dataset\n",
    "- We will get the same train and test dataset across different executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18961868-d767-47c9-bcaa-8c9506ca8a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 12]\n",
      " [ 3 13]\n",
      " [ 4 14]\n",
      " [ 5 15]\n",
      " [ 6 16]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 9 19]\n",
      " [10 20]]\n",
      "\n",
      "**************************************************\n",
      "[[10 20]\n",
      " [ 2 12]\n",
      " [ 7 17]\n",
      " [ 8 18]\n",
      " [ 4 14]\n",
      " [ 1 11]\n",
      " [ 6 16]]\n",
      "\n",
      "[[ 3 13]\n",
      " [ 9 19]\n",
      " [ 5 15]]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array and splitting  (one time splitting)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset=np.arange(1,21).reshape(2,10).T\n",
    "print(dataset)\n",
    "print()\n",
    "print(50*'*')\n",
    "X_train,X_test=train_test_split(dataset,random_state=0)\n",
    "print(X_train)\n",
    "print()\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef153a93-8d0a-4569-8372-e512f7ae6f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
